# NetworkX Developer Discussions: March 13th, 2024

Previous meeting notes available [here](https://github.com/networkx/archive/tree/main/meetings). Please feel free to add topics for discussion and news items below.
Meeting link: https://colgate.zoom.us/j/92619161786

**In attendance**: Ross, Rick, Erik, Matt, Dan, Aditi

## Welcome and news

- Sentry donation hasn't arrived in opencollective yet, but maybe I don't know how to look it up (or maybe opencollective is not the way to see contributions). A second payment was automatically initiated from thanks.dev for March
    - Still nothing in opencollective. Maybe we should have arranged for the payment to go to github sponsors (but there is a small fee for that I guess.). Or maybe we need to contact nnumfocus to see if the donation first goes through another system before showing up on opencollective.  
- GSOC: we have been accepted into the NumFOCUS projects for GSOC. So it should be similar to previous years.
    - March 18 will open the application period. Closes April 2.

## Important dates/deadlines

- GSoC application period:
  * Opens this week
  * Closes April 2nd

- NX 3.3 (tentatively scheduled for March 29, 2024)
    - Numpy timeline ~6 weeks for RC. (branching for rc0 3/3/24)
    - only PR that might be affected is NEP 51
      * In!
    - Dispatching PRs might need merging before release (and before talks) before March 18th (go / no go --- next week)

- Upcoming dates/conferences:
    - NetSci https://netsci2024.com/en/satellites June 16-21 QuÃ©bec City, Canada
      - "Would NetworkX would be able to send someone to NetSci this year who could teach (or better: co-teach) a workshop on network analysis in Python using multiple different packages (igraph, NetworkX, etc.)."
      - Matt is available. What materials can we provide to help that? 
      - https://ericmjl.github.io/Network-Analysis-Made-Simple/
    - SciPy 2024 (Seattle)
        - https://www.scipy2024.scipy.org
        - July 8 - 14, 2024
        - 2 Talks submitted. 1) Rick (& others) and 2) Dan (& Rick) to talk about backends.
    - PyCon: May 15-23. (Pittsburg) Talk isaccepted! Erik & ?Mridul & ?Rick
    - GSOC student applications open in March
      * TODO: Update projects page
    - GTC March 18 9:30am PT [talk accepted](https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&search=networkx#/session/1694165448219001rnXr)
    - [Scientific Python Developer Summit](https://scientific-python.org/summits/developer/2024/) 3-7 June, Seattle
    - PyData London (Erik talk) June 15-16 CFP March 4
      - Submitted: "Powering Graph ML with NetworkX Backends" ErikW and AaronZL
    - PyData Paris Sep 25-26 CFP April 8 (prob Erik)

## Follow-up from last week

- NumPy 2.0 scalars is merged
  * Note: be aware of potential test failures for new fns!
  * Let's add a note to contributor guide about ensuring return values are not numpy scalars.
  * https://github.com/rossbar/networkx/actions/runs/8218084712/job/22474514850
  
- Forceatlas2 layout: https://github.com/networkx/networkx/pull/5392
  * Some recent activity; would characterize as "needs decision" state
  * Jarrod will ping gephi on it :tada: 
    - ping Jarrod on gephi-contact
    - ```@mbastian We are interested in validating this implementation of ForceAtlas2 against Gephi. The author wasn't able to get gephi to use an initial layout through the cli (see https://github.com/networkx/networkx/pull/5392#issuecomment-1077289167)```

## Topics

- `nx.config`
  * Discussion about future use and location of the dict
  * `scikit-learn`-style API?
    - `get_config()`, `set_config(**kwargs)`, `with config_context(**kwargs):`
    - https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/_config.py
  * New work: now a class instead of a dict, ready for a new round of :eyes:
  
- `Graph._cache`
    - When should the cached values be cleared? Should it depend on what is changed?
    - Should we try to identify when data attributes have been changed?
    - How to identify changes like `nodelist` for `to_scipy_sparse_array`
    - hash of the inputs to the function? hash of the data values in the graph?
    - name of function and str of inputs (while forcing users to turn on caching using a keyword arg that warns them not to change the graph between calls. Only functions that know to turn on caching could use it.)
    - maybe put caching flags in the config?
    
- Viz kwarg for axis ticks: https://github.com/networkx/networkx/pull/6018

- Exercise: review current & desired return types for all shortest path functions (weighted, unweighted, source, target, and length)
  - possibly generate a table https://networkx.org/documentation/latest/reference/algorithms/shortest_paths.html
  - maybe GSoC project?

## High priority

- time to go through PRs and find high priority or neglected items
  - Remember the Pledge! Goal: open PR count -> 0.

- prioritize Erik's PRs.  e.g.  caching PR

### Possible Projects
 
- To make contributions of new algorithms more compelling, it would be helpful to have a large set of tests showing what are the expected values and how it is different from other measures of centrality. [add this discussion result to the contributors FAQ] (@rossbar)

- For centrality, a mentored project could test and document the various centrality measures and their differences on a suite of graphs. [add to list in the docs!]

- Idea discussed related to new features. Should we start naming new modules with a leading underscore? This would simplify tab-completion by hiding modules.

- Visualization features/improvements
  * Draw MultiDiGraph edges and labels qa7008 [#7010](https://github.com/networkx/networkx/pull/7010) 
    - Lots of code!
  * Marker intersection PR for drawing [#4601](https://github.com/networkx/networkx/pull/4601)

## Dispatch topic 

- naming of backend packages. [#6883](https://github.com/networkx/networkx/pull/6883) This means nx-parallel is the package, then we import with nx_parallel.

## NXEP topic

  * [NXEP 3] Graph Builders and Generators (https://github.com/networkx/networkx/blob/main/doc/developer/nxeps/nxep-0003.rst)
    * [New June 14] How to handle the docs for two functions nx.path_graph and nx.path_graph_generator
    * [New June 14] Do we have a decorator create two functions in the main namespace? Or just hardcode the two functions in the module? Ideas on cutting down duplication of code/effort?
    * We should have a conversation about how dispatching should interact with these graph builders.
    * Rewritten Text merged! :tada: in [#6648](https://github.com/networkx/networkx/pull/6648)
    * Maybe make private functions that are generators. Could start now. Could be used to see how much impact it has on speed, memory use, etc. We can test it out privately and see what are the advantages. 
    * Motivation to make these changes for random graphs: [#5672](https://github.com/networkx/networkx/pull/5672) requests `create_using` arg for random graph generators so that subclass of Graph can be built by the generator
  * Could we add the NXEP status to the documentation page with the list of NXEPs and their titles?  Maybe like: `NXEP 0 - Accepted - Purpose and process`. This might require changes to sphinx/autodoc. Any easy way to annotate within `index.rst` and still allow the autodoc links to be formed? 
  * According to NXEP 0 we should be converting NXEPs that are implemented to the status: Final...  not Accepted. Perhaps a PR to do that for 0, 1, 2 and 4 is in order. 
  * NXEP 4: TODO [name=rossbar] - propose acceptance on mailing list

## Long-term tracking items

- Org-level accounts on PyPi - we have applied, waiting to hear back
  * Submitted April 25, got confirmation. waiting for authorization

- nx pkg namesquatting on Pypi: https://pypi.org/project/nx/#description
  * TODO: https://github.com/pypi/support/issues - PEP 541

SPECS
-----
  - [SPEC 7: random seeding](https://github.com/scientific-python/specs/pull/180#issuecomment-1570678859)
    - We have NXEP-4 to discuss this https://networkx.org/documentation/stable/developer/nxeps/nxep-0004.html
    - Ross will review and coauthor SPEC 7
  
  - https://scientific-python.org/specs/
      - nx endorsed 0, 1, and 4
      - what about the [Accessibility SPEC 3?]( https://scientific-python.org/specs/spec-0003/) We support the accessibility goals and ideas, but most changes would need to be put in sphinx themes and other upstream tools. How do we support that and what would endorsing the SPEC mean for this topic?

Datasets
* Patent graph: https://snap.stanford.edu/data/cit-Patents.html
* Potentially interesting - knowledge graph/scientific publications: https://arxiv.org/abs/2308.03671
* Gene Regulation Networks http://www.grndb.com/
* Stanford SNAP datasets: http://snap.stanford.edu/data/index.html
* TAMU sparse: http://sparse.tamu.edu/
  * Note: contains many SNAP datasets
- Add a datasets gallery?

- Do we have any info about what functions are most used/popular?
  * not from the survey - request for next iteration!
  * Guen (@guenp) is working with Matt (@mdhaber) on telemetry
  * We could look at networkx itself to see how often individual functions are called in the codebase itself
    * Jim Pivarski (@jpivarski) is working on a tool that would help with this at the May 2023 developer summit. Results?

TODO from [igraph meeting](https://igraph.org/workshop.html) (June 21-22)
  - Group will be formed, e.g. "network science software sustainability group"
    * Convince other organizations/conferences to contribute to OSS Network software
  - Met graphtool dev, igraph devs, gephi
    * It'd be nice to have a list of github handles for folks from different communities
      - e.g. the gephi folks are GEXF experts, it'd be great to know who to ping!
  - Discussions on file format standarization for graph data (i.e. json-like)
  - Leiden is awesome
  - Basic dispatching discussion: topical discussion, folks are aware
  - More cross-community coordination to come!

Teams Changes:
- What else needs to be done with Teams changes? 
  Anybody else to add? Changes to "owners"?
    * 3 proposed teams [not agreed upon yet]:
      - maintainers (with commit rights)
      - triage (with triage rights)
      - emeritus (no active rights)
    * vs keep current teams and governance documents and just update the role for core developer from triage to write  [decided to switch to write access] Updated the core team too and removed emeritus owners.

Adopt `pyproject.toml`?
  - https://github.com/networkx/networkx/pull/6774 (merged)
  - https://github.com/networkx/networkx/pull/6780 (merged)
  - https://github.com/pygraphviz/pygraphviz/pull/471

Other items:
- helpful to have a place for best-practices like nbunch, view vs dict, subgraph vs subgraph.copy()
  * nx-guides would be a good place for this!

- Keyword-only and maybe position-only input. Candidate subpackage to start changing code to keyword-only is the nx_pylab. (see [SLEP009](https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep009/proposal.html) for how sklearn did this)

- We should try to automate the release process as much as possible so that we could remove a human from the release process. conda-forge has a very automated release system. Would a SPEC covering automated releases be reasonable?
    - Not clear what the advanatges of automating the release process would be. The process is [documented](https://github.com/networkx/networkx/blob/main/doc/developer/release.rst) What would make this better?
    - Why would automating things further not cause problems?
    - That's agree to make sure a PR's title is helpful and descriptive before merging it.

- Review public interface: For v4.0 we should be looking at the import structure?  Some subpackages are not imported to the main namespace. We have decided that based on history of how they were first committed. Is there a good way to decide which should require an extra referal: `network.community.modularity` instead of `networkx.modularity`?
  - First decision: what do we *want* the interface to be?
  - Module/pkg `__dir__` provides a nice way to modify discoverability of modules/packages **without** breaking existing code
  - NX-guide idea: model/visualize the package as a DAG (thanks Matt!)

- keywords arrows, arrowstyle, connectionstyle. Can we improve this interface? [#5694](https://github.com/networkx/networkx/pull/5694) and a link to the [current interface](https://github.com/networkx/networkx/blob/2c904d18dc79df3acd64495ef64c6ff4674992a0/networkx/drawing/nx_pylab.py#L537)
    - Now raise UserWarnings when users request features that are not available for the underlying edge-viz object (e.g. LineCollection)
    - Is there a better, more wholistic solution?
    - Need to indicate:
      o FancyArrowPatch or LineCollection
      o The arrowstyle (head or not or both, etc)
      o The connectionstyle (arc bendable etc)
    - Maybe changing the name of `arrows` to `fancyedges` would help
    - New logic could be:  If non-default value for either arrowstyle or connectionstyle then switch to FancyArrowPatch.

- Property-based testing
  * Check out `hypothesis` for setting up property-based testing
  * Developing good property-based tests:
    - Reference "naive" (but correct) implementation
    - Generate random graphs, evaluate them for the property you want
    - Pump these through the naive implementation and collect interesting cases for test suite

- Temporal networks: how to think about these
  * seems to be a lot of interest from different communities, but no standard approach yet...
  * Having a use-case to drive the design of a data structure would be good
  
- nx-guides
  * We need a contributor guide :book: [name=Mridul]
  * Dependency management for tutorials - how to strike a balance between tools people use and maintainability

- New contributors
  * So many good students/contributions - how do we keep the ball rolling (even if we can only accept 1 or a subset of them for this round)
    - Add something to contributor guide about where to look for good issues (e.g. add missing docstring examples)
    - Link to [first issue tag](https://github.com/networkx/networkx/labels/Good%20First%20Issue) on github?
    
- Revisiting our pytest `slow` mark:
  * The `slow` tests are run w/ each push/PR in the coverage job; however, it's not necessarily true that the slow tests improve coverage!
  * Could save a lot of CI time by having a separate category (e.g. `pytest.mark.comprehensive`?) that is for tests that are slow but *don't* affect coverage. These could be run less frequently (scheduled job?) and potentially save several minutes for each push
    - General consensus: seems like a good idea
    - ~~(Jarrod) maybe worth waiting until after the code removal sprint?~~
      - deprecated code removed

- Other CI-saving ideas
    - All tests should depend on the lint action, so all the other tests fail fast.

## Discussion

- [ ] Social media
    * NetworkX twitter
    * blog.scientific-python.org