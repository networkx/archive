# NetworkX Developer Discussions: June 7th, 2023

Previous meeting notes available [here](https://github.com/networkx/archive/tree/main/meetings). Please feel free to add topics for discussion and news items below.

**In attendance:** 

## Welcome and news

* New meeting time for Summer 2023: Wednesday 2PM EDT, 11AM PDT
* NumFOCUS small developoment grant was awarded :tada: for Ross and student Nilo to work this summer on property based testing for NetworkX. 
  * Tentative start date: July 5th(ish)
 * https://igraph.org/workshop.html (June 21-22)

## Important dates/deadlines

* SciPy conference (event is July 9-16)
  * NetworkX/dispatching tutorial has been waitlisted
* PyCon Colombia has accepted a tutorial (early June) :tada: 
* GSoC/Outreachy Application: Wait for responses from GSOC and Outreachy
  - Navya and Kavish have been accepted for Outreachy and GSoC funding!  :tada:

## Follow-up from last week

- Org-level accounts on PyPi - we have applied, waiting to hear back
  * Submitted April 25, got confirmation. waiting for authorization

## Topics

- [SPEC 7: random seeding](https://github.com/scientific-python/specs/pull/180#issuecomment-1570678859)

- https://pypi.org/project/pygraphviz/1.11rc1/
  - swig 4.1.1 update
  - misc updates

- https://scientific-python.org/specs/
    - nx endorsed 0, 1, and 4

- nightly wheels
    - https://anaconda.org/scientific-python-nightly-wheels/

- How is np.nan treated by pickle? https://github.com/networkx/networkx/discussions/6721
    - np.nan is valid node in networkx (it's not technically None)


- Depth limit for DFS: Path[^1] forward
  * https://github.com/networkx/networkx/issues/6479
  
   * one idea: Do we add a new module for iterated, depth-limited search and keep depth_limit out of the current dfs search?

- [^1]: ha

- Namespace review:
  * TODO: Review dispatching PR for interesting discussion wrt namespace review
    - https://github.com/networkx/networkx/pull/6688
  * Be on the lookout for a second, related PR!

- Do we have any info about what functions are most used/popular?
  * not from the survey - request for next iteration!
  * We could look at networkx itself to see how often individual functions are called in the codebase itself
    * Jim Pivarski (@jpivarski) is working on a tool that would help with this at the developer summit this week. 

## NXEP topic of the week
  * Could we add the status to the documentation page with the list of NXEPs and their titles?  Maybe like: `NXEP 0 - Accepted - Purpose and process`. This might require changes to sphinx/autodoc. Any easy way to annotate within `index.rst` and still allow the autodoc links to be formed? 
  * This week, [NXEP 3](https://github.com/networkx/networkx/blob/main/doc/developer/nxeps/nxep-0003.rst) The controvercial aspects seem to be:
    * There is a desire to not remove `create_using`
    * the complication of allowing a CustomGraph attribute
    * We should also have a conversation about how dispatching should interact with graph builders.
    * Rewritten Text proposed in [#6648](https://github.com/networkx/networkx/pull/6648)
    * Naming discussion:
        * As written we use `nx.path_graph.edges_plus(5)` and `nx.path_graph.edges(5)`.  Should it be `nx.path_graph.generator(5)` and `nx.path_graph.edges_only(5)`?
        * Should this be part of the public API? Doesn't look nice... maybe for advanced users? How do we document that then...
        * Maybe make private functions that are generators. Could start now. Could be used to see how much impactit has on speed, memory use, etc. We can test it out privately and see what are the advantages. 
  * According to NXEP 0 we should be converting NXEPs that are implemented to the status: Final...  not Accepted. Perhaps a PR to do that for 0, 1, 2 and 4 is in order. 
  * NXEP 4: TODO [name=rossbar] - propose acceptance on mailing list

## Long-term tracking items

- What else needs to be done with Teams changes? 
  What level for Paula? Anybody else to add? Last summer?
  We have a number of "owners" of the networkx account. They should be updated.
    * 3 proposed teams [not agreed upon yet]:
      - maintainers (with commit rights)
      - triage (with triage rights)
      - emeritus (no active rights)
    * vs keep current teams and governance documents and just update the role for core developer from triage to write  [decided to switch to write access] Updated the core team too and removed emeritus owners.

- Adopt `pyproject.toml`?
  * [This article was a nice overview](https://snarky.ca/what-the-heck-is-pyproject-toml/)
  * Since NX doesn't have build deps, there's no strong motivation to do so other than "other projects are doing it"
  * Potential "benefit" - store metadata/configs for additional tooling (e.g. type checkers, linters) in one place. [PEP 621](https://peps.python.org/pep-0621/) 
  * Jarrod reports that there may be many changes to the systems in the lead up to Python 3.12. So maybe we should delay consideration of changing to this until then. If we do adopt pyproject.toml, we may want to autogenerate it from the requirements file. For example, see what we did in scikit-image:
https://github.com/scikit-image/scikit-image/blob/main/tools/generate_pyproject.toml.py
  * Jarrod reports that at the moment every config piece can't be put into `pyproject.toml`.  He tried it with skimage. Jarrod will take a shot at converting configs to pyproject.toml (ruff will be able to go there too)
  * goals: combine as much as possible. and make pyproject.toml autogenerated.
  * [Jarrod] Not sure if this is worth doing now. It looks like it would increase number of files and lines of code without adding any functionality.

- helpful to have a place for best-practices like nbunch, view vs dict, subgraph vs subgraph.copy()
  * nx-guides would be a good place for this!

- Keyword-only and maybe position-only input. Candidate subpackage to start changing code to keyword-only is the nx_pylab. (see [SLEP009](https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep009/proposal.html) for how sklearn did this)

- We should try to automate the release process as much as possible so that we could remove a human from the release process. conda-forge has a very automated release system. Would a SPEC covering automated releases be reasonable?
    - Not clear what the advanatges of automating the release process would be. The process is [documented](https://github.com/networkx/networkx/blob/main/doc/developer/release.rst) What would make this better?
    - Why would automating things further not cause problems?
    - That's agree to make sure a PR's title is helpful and descriptive before merging it.

- Review public interface: For v4.0 we should be looking at the import structure?  Some subpackages are not imported to the main namespace. We have decided that based on history of how they were first committed. Is there a good way to decide which should require an extra referal: `network.community.modularity` instead of `networkx.modularity`?
  - First decision: what do we *want* the interface to be?
  - Module/pkg `__dir__` provides a nice way to modify discoverability of modules/packages **without** breaking existing code
  - NX-guide idea: model/visualize the package as a DAG (thanks Matt!)

- keywords arrows, arrowstyle, connectionstyle. Can we improve this interface? [#5694](https://github.com/networkx/networkx/pull/5694) and a link to the [current interface](https://github.com/networkx/networkx/blob/2c904d18dc79df3acd64495ef64c6ff4674992a0/networkx/drawing/nx_pylab.py#L537)
    - Now raise UserWarnings when users request features that are not available for the underlying edge-viz object (e.g. LineCollection)
    - Is there a better, more wholistic solution?
    - Need to indicate:
      o FancyArrowPatch or LineCollection
      o The arrowstyle (head or not or both, etc)
      o The connectionstyle (arc bendable etc)
    - Maybe changing the name of `arrows` to `fancyedges` would help
    - New logic could be:  If non-default value for either arrowstyle or connectionstyle then switch to FancyArrowPatch.

- Property-based testing
  * Check out `hypothesis` for setting up property-based testing
  * Developing good property-based tests:
    - Reference "naive" (but correct) implementation
    - Generate random graphs, evaluate them for the property you want
    - Pump these through the naive implementation and collect interesting cases for test suite

- Temporal networks: how to think about these
  * seems to be a lot of interest from different communities, but no standard approach yet...
  * Having a use-case to drive the design of a data structure would be good
  
- nx-guides
  * We need a contributor guide :book: [name=Mridul]
  * Dependency management for tutorials - how to strike a balance between tools people use and maintainability

- New contributors
  * So many good students/contributions - how do we keep the ball rolling (even if we can only accept 1 or a subset of them for this round)
    - Add something to contributor guide about where to look for good issues (e.g. add missing docstring examples)
    - Link to [first issue tag](https://github.com/networkx/networkx/labels/Good%20First%20Issue) on github?
    
- Revisiting our pytest `slow` mark:
  * The `slow` tests are run w/ each push/PR in the coverage job; however, it's not necessarily true that the slow tests improve coverage!
  * Could save a lot of CI time by having a separate category (e.g. `pytest.mark.comprehensive`?) that is for tests that are slow but *don't* affect coverage. These could be run less frequently (scheduled job?) and potentially save several minutes for each push
    - General consensus: seems like a good idea
    - ~~(Jarrod) maybe worth waiting until after the code removal sprint?~~
      - deprecated code removed

- Other CI-saving ideas
    - All tests should depend on the lint action, so all the other tests fail fast.

## Discussion

- [ ] Social media
    * NetworkX twitter
    * blog.scientific-python.org