# NetworkX Developer Discussions: Dec 18th, 2025

[Previous meeting notes](https://github.com/networkx/archive/tree/main/meetings) are available. 
Please add News, Discussion and Topics below.
Meeting link: https://colgate.zoom.us/j/92619161786

## Meeting Info
- Meeting time Thursdays 12-1 ET (5pm UTC)
- [dispatching meeting](https://hackmd.io/rqs_pWMxSLmICXCpI3w-Ug) 1st Tuesday of the month 11:30-12:30 ET 
- [Publicly available analytics for our docs pages](https://views.scientific-python.org/networkx.org)

**In attendance**: Dan, Ross, Rick

## Admin stuff
- Nice freethreading docs overview: https://py-free-threading.github.io/
 
## Topics
- [parallel doc build in CI: #8344](https://github.com/networkx/networkx/pull/8344)

- [walk creator #8383](https://github.com/networkx/networkx/pull/8383) Should this create one walk for each starting node? Or one walk for the prescribed node. Difference is looping in the function or outside the function -- and are the nodes the likely loop?

- Thoughts about deprecating `minimum_cut_value` and `maximum_flow_value`? https://github.com/networkx/networkx/issues/8393



- [TODO] nx-parallel release with next networkx release

- Refactor nx.draw to [use display under-the-hood PR 8255](https://github.com/networkx/networkx/pull/8255)
    - run drawing heavy suites from outside the tests:
        - gallery
        - nx-guides
- Probably should Update docs to point to iplotx and/or display as needed. (Action: open an issue)

### Action Items
- We should help out contributors who have a single function optimization for their use-case. Probably by making backends with one function easy to use/share/morph.
- `iplotx` (Fabio Zanini [package for drawing igraph and NetworkX graphs](https://github.com/fabilab/iplotx)) 
    - [Gallery](https://iplotx.readthedocs.io/en/latest/gallery/index.html) 


## Old Topics
- Benchmarking: Building off what Derek put together.
    - pytest.benchmark vs asv for benchmarks? Are there better tools. 
        - What did Derek use in the end? Are there tools within that we could build on.
    - Three aspects to benchmarking:
        - presentation of results
        - running and data storage (ascii/csv/json, etc)
        - authoring (which datasets as well as parameters of the functions)
    - Can we put together a set of functions and datasets?
        - Create a NetworkX suite of graph benchmarks